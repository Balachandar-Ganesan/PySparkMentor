{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "CgW352SgmXiQ",
        "outputId": "de931e14-8b45-4c35-c68e-94fd8f0aad67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,676 kB]\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,939 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,363 kB]\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,723 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,934 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,517 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,245 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,546 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [83.2 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\n",
            "Fetched 30.5 MB in 8s (3,678 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "35 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "tar: spark-3.2.1-bin-hadoop3.2.tgz: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.11/dist-packages (0.10.9.7)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/usr/local/lib/python3.11/dist-packages/pyspark'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "#Check this site for the latest download link https://www.apache.org/dyn/closer.lua/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "!pip install py4j\n",
        "\n",
        "import os\n",
        "import sys\n",
        "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "# os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\"\n",
        "\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "findspark.find()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "\n",
        "from pyspark.sql import DataFrame, SparkSession\n",
        "from typing import List\n",
        "import pyspark.sql.types as T\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "spark= SparkSession \\\n",
        "       .builder \\\n",
        "       .appName(\"UltimateSpark\") \\\n",
        "       .getOrCreate()\n",
        "\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "Y5zg1UzzmpbP",
        "outputId": "e2fa73e9-4e5e-4a7a-bbb0-66606ceefaa1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x79a8046b8bd0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://5ea553b7aa85:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>UltimateSpark</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TNBokRq_aTYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataDictionary = [\n",
        "        ('James',{'hair':'black','eye':'brown'}),\n",
        "        ('Michael',{'hair':'brown','eye':None}),\n",
        "        ('Robert',{'hair':'red','eye':'black'}),\n",
        "        ('Washington',{'hair':'grey','eye':'grey'}),\n",
        "        ('Jefferson',{'hair':'brown','eye':''})\n",
        "        ]\n",
        "\n",
        "df = spark.createDataFrame(data=dataDictionary, schema = ['name','properties'])\n",
        "df.printSchema()\n",
        "df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0usQWN3q2N5d",
        "outputId": "d8499d9e-4957-43b3-fefa-161697a8e3ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- properties: map (nullable = true)\n",
            " |    |-- key: string\n",
            " |    |-- value: string (valueContainsNull = true)\n",
            "\n",
            "+----------+-----------------------------+\n",
            "|name      |properties                   |\n",
            "+----------+-----------------------------+\n",
            "|James     |{eye -> brown, hair -> black}|\n",
            "|Michael   |{eye -> NULL, hair -> brown} |\n",
            "|Robert    |{eye -> black, hair -> red}  |\n",
            "|Washington|{eye -> grey, hair -> grey}  |\n",
            "|Jefferson |{eye -> , hair -> brown}     |\n",
            "+----------+-----------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(\"James\",\"\",\"Smith\",\"36636\",\"M\",60000),\n",
        "        (\"Michael\",\"Rose\",\"\",\"40288\",\"M\",70000),\n",
        "        (\"Robert\",\"\",\"Williams\",\"42114\",\"\",400000),\n",
        "        (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\",500000),\n",
        "        (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",0)]\n",
        "\n",
        "columns = [\"first_name\",\"middle_name\",\"last_name\",\"v1\",\"gender\",\"salary\"]\n",
        "pysparkDF = spark.createDataFrame(data = data, schema = columns)\n",
        "pysparkDF.printSchema()\n",
        "pysparkDF.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUn9_x-W2N62",
        "outputId": "5afccb82-2833-4bfc-fe00-7ddbab4772ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- first_name: string (nullable = true)\n",
            " |-- middle_name: string (nullable = true)\n",
            " |-- last_name: string (nullable = true)\n",
            " |-- dob: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- salary: long (nullable = true)\n",
            "\n",
            "+----------+-----------+---------+-----+------+------+\n",
            "|first_name|middle_name|last_name|dob  |gender|salary|\n",
            "+----------+-----------+---------+-----+------+------+\n",
            "|James     |           |Smith    |36636|M     |60000 |\n",
            "|Michael   |Rose       |         |40288|M     |70000 |\n",
            "|Robert    |           |Williams |42114|      |400000|\n",
            "|Maria     |Anne       |Jones    |39192|F     |500000|\n",
            "|Jen       |Mary       |Brown    |     |F     |0     |\n",
            "+----------+-----------+---------+-----+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType, StructField, StringType,IntegerType\n",
        "dataStruct = [((\"James\",\"\",\"Smith\"),\"36636\",\"M\",\"3000\"), \\\n",
        "      ((\"Michael\",\"Rose\",\"\"),\"40288\",\"M\",\"4000\"), \\\n",
        "      ((\"Robert\",\"\",\"Williams\"),\"42114\",\"M\",\"4000\"), \\\n",
        "      ((\"Maria\",\"Anne\",\"Jones\"),\"39192\",\"F\",\"4000\"), \\\n",
        "      ((\"Jen\",\"Mary\",\"Brown\"),\"\",\"F\",\"-1\") \\\n",
        "]\n",
        "\n",
        "schemaStruct = StructType([\n",
        "        StructField('name', StructType([\n",
        "             StructField('firstname', StringType(), True),\n",
        "             StructField('middlename', StringType(), True),\n",
        "             StructField('lastname', StringType(), True)\n",
        "             ])),\n",
        "          StructField('v1', StringType(), True),\n",
        "         StructField('gender', StringType(), True),\n",
        "         StructField('salary', StringType(), True)\n",
        "         ])\n",
        "\n",
        "\n",
        "df = spark.createDataFrame(data=dataStruct, schema = schemaStruct)\n",
        "df.printSchema()\n",
        "df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XkHOKEH24AK",
        "outputId": "5e2d2b62-a8f6-4834-9aef-da7189e3e8a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: struct (nullable = true)\n",
            " |    |-- firstname: string (nullable = true)\n",
            " |    |-- middlename: string (nullable = true)\n",
            " |    |-- lastname: string (nullable = true)\n",
            " |-- dob: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- salary: string (nullable = true)\n",
            "\n",
            "+--------------------+-----+------+------+\n",
            "|name                |dob  |gender|salary|\n",
            "+--------------------+-----+------+------+\n",
            "|{James, , Smith}    |36636|M     |3000  |\n",
            "|{Michael, Rose, }   |40288|M     |4000  |\n",
            "|{Robert, , Williams}|42114|M     |4000  |\n",
            "|{Maria, Anne, Jones}|39192|F     |4000  |\n",
            "|{Jen, Mary, Brown}  |     |F     |-1    |\n",
            "+--------------------+-----+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv('sample_data/california_housing_train.csv',inferSchema=True,header=True)"
      ],
      "metadata": {
        "id": "4mATU85H55CV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-5di2xf6QWC",
        "outputId": "238ab487-cae2-4346-a16d-6df8f542d087"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- longitude: double (nullable = true)\n",
            " |-- latitude: double (nullable = true)\n",
            " |-- housing_median_age: double (nullable = true)\n",
            " |-- total_rooms: double (nullable = true)\n",
            " |-- total_bedrooms: double (nullable = true)\n",
            " |-- population: double (nullable = true)\n",
            " |-- households: double (nullable = true)\n",
            " |-- median_income: double (nullable = true)\n",
            " |-- median_house_value: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPHnJ1yN6QXO",
        "outputId": "c654c33f-bf03-49ed-8162-c7239eaf330b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|  -114.31|   34.19|              15.0|     5612.0|        1283.0|    1015.0|     472.0|       1.4936|           66900.0|\n",
            "|  -114.47|    34.4|              19.0|     7650.0|        1901.0|    1129.0|     463.0|         1.82|           80100.0|\n",
            "|  -114.56|   33.69|              17.0|      720.0|         174.0|     333.0|     117.0|       1.6509|           85700.0|\n",
            "|  -114.57|   33.64|              14.0|     1501.0|         337.0|     515.0|     226.0|       3.1917|           73400.0|\n",
            "|  -114.57|   33.57|              20.0|     1454.0|         326.0|     624.0|     262.0|        1.925|           65500.0|\n",
            "|  -114.58|   33.63|              29.0|     1387.0|         236.0|     671.0|     239.0|       3.3438|           74000.0|\n",
            "|  -114.58|   33.61|              25.0|     2907.0|         680.0|    1841.0|     633.0|       2.6768|           82400.0|\n",
            "|  -114.59|   34.83|              41.0|      812.0|         168.0|     375.0|     158.0|       1.7083|           48500.0|\n",
            "|  -114.59|   33.61|              34.0|     4789.0|        1175.0|    3134.0|    1056.0|       2.1782|           58400.0|\n",
            "|   -114.6|   34.83|              46.0|     1497.0|         309.0|     787.0|     271.0|       2.1908|           48100.0|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.total_rooms"
      ],
      "metadata": {
        "id": "b0y8SQdo6ZAg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea922dae-cd56-412b-8496-13a62ccf1215"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Column<'total_rooms'>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(df.total_rooms).show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TB3IfGKo7z6N",
        "outputId": "5e96296b-34fb-4d79-871e-416e7445cd14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|total_rooms|\n",
            "+-----------+\n",
            "|     5612.0|\n",
            "|     7650.0|\n",
            "|      720.0|\n",
            "|     1501.0|\n",
            "|     1454.0|\n",
            "+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(df[\"total_rooms\"]).show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5OcPyN57_yb",
        "outputId": "6e776d88-c576-40a4-cf3c-5f97724ea86a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|total_rooms|\n",
            "+-----------+\n",
            "|     5612.0|\n",
            "|     7650.0|\n",
            "|      720.0|\n",
            "|     1501.0|\n",
            "|     1454.0|\n",
            "+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "df.select([\"*\"]).show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BShi_qBo7_zt",
        "outputId": "28ad4d18-711a-4f72-a134-c43788cd0fe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|  -114.31|   34.19|              15.0|     5612.0|        1283.0|    1015.0|     472.0|       1.4936|           66900.0|\n",
            "|  -114.47|    34.4|              19.0|     7650.0|        1901.0|    1129.0|     463.0|         1.82|           80100.0|\n",
            "|  -114.56|   33.69|              17.0|      720.0|         174.0|     333.0|     117.0|       1.6509|           85700.0|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(df.total_rooms.alias(\"TotalRooms\")).show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QQ7aiVg8q6d",
        "outputId": "b748658e-45a9-47ee-d03c-abf35bd04250"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+\n",
            "|TotalRooms|\n",
            "+----------+\n",
            "|    5612.0|\n",
            "|    7650.0|\n",
            "|     720.0|\n",
            "+----------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.orderBy(df.total_rooms.desc()).show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJWF-QyS8q70",
        "outputId": "44a52905-8ffc-4a48-da58-7cdb633cf06e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|  -117.74|   33.89|               4.0|    37937.0|        5471.0|   16122.0|    5189.0|       7.4947|          366300.0|\n",
            "|  -121.79|   36.64|              11.0|    32627.0|        6445.0|   28566.0|    6082.0|       2.3087|          118800.0|\n",
            "|  -117.78|   34.03|               8.0|    32054.0|        5290.0|   15507.0|    5050.0|       6.0191|          253900.0|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(df.total_rooms,df.population).orderBy(df.total_rooms.desc()).show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dNH6nGD-tYl",
        "outputId": "0c56f416-0ed5-4889-89ea-0f3882976b94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----------+\n",
            "|total_rooms|population|\n",
            "+-----------+----------+\n",
            "|    37937.0|   16122.0|\n",
            "|    32627.0|   28566.0|\n",
            "|    32054.0|   15507.0|\n",
            "+-----------+----------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(df.median_income.cast(\"int\")).show(4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqPebkgh-tZ_",
        "outputId": "ac449644-2171-4f7e-accd-46559ed7f3db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+\n",
            "|median_income|\n",
            "+-------------+\n",
            "|            1|\n",
            "|            1|\n",
            "|            1|\n",
            "|            3|\n",
            "+-------------+\n",
            "only showing top 4 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(df.total_rooms).where(df.median_income.between(3,10)).show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDWnYDIy_U9e",
        "outputId": "f0f741f5-c7eb-43a2-ecbc-4737c867bea9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|total_rooms|\n",
            "+-----------+\n",
            "|     1501.0|\n",
            "|     1387.0|\n",
            "|     2478.0|\n",
            "+-----------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(df.total_rooms).where(df.total_rooms.isin(1501,1387)).show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSBXR8AsaVop",
        "outputId": "9ae5a38e-9989-4074-f8e6-f581ece17b08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|total_rooms|\n",
            "+-----------+\n",
            "|     1501.0|\n",
            "|     1387.0|\n",
            "|     1387.0|\n",
            "+-----------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import Row\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjUPbLzwdInC",
        "outputId": "a7e4867d-a57e-435f-e121-974776716dd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------+\n",
            "| id|   value|\n",
            "+---+--------+\n",
            "|  1|Training|\n",
            "+---+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfTest = spark.read.csv('sample_data/california_housing_test.csv',inferSchema=True,header=True)"
      ],
      "metadata": {
        "id": "63i737XyXut5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfTest.select(dfTest.longitude,dfTest.latitude).show(4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XGbC3oPXuvA",
        "outputId": "df00c5b3-3fb3-485a-c3b0-37e8a9dd5b46"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+\n",
            "|longitude|latitude|\n",
            "+---------+--------+\n",
            "|  -122.05|   37.37|\n",
            "|   -118.3|   34.26|\n",
            "|  -117.81|   33.78|\n",
            "|  -118.36|   33.82|\n",
            "+---------+--------+\n",
            "only showing top 4 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfTest=dfTest.select(dfTest.longitude,dfTest.latitude).distinct()"
      ],
      "metadata": {
        "id": "noprPEbgYjpa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sYpRr_VVa8uM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "WtauPTLja8va",
        "outputId": "54d5a6f1-6e0b-4ca4-f926-cec299be9726"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=UltimateSpark, master=local[*]) created by getOrCreate at <ipython-input-2-8800bcdda998>:11 ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-120c2e78630b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"local\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"SparkAdditionalPackage\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[1;32m    199\u001b[0m             )\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             self._do_init(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0;31m# Raise error if there is already a running Spark context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m    450\u001b[0m                         \u001b[0;34m\"Cannot run multiple SparkContexts at once; \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m                         \u001b[0;34m\"existing SparkContext(app=%s, master=%s)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=UltimateSpark, master=local[*]) created by getOrCreate at <ipython-input-2-8800bcdda998>:11 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sparkContext.addPyFile(\"https://raw.githubusercontent.com/gbrueckl/Fabric.Toolbox/main/DataEngineering/Library/VisualizeExecutionPlan.py\")\n",
        "from VisualizeExecutionPlan import show_plan"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBAVEy7RaGA-",
        "outputId": "c3980745-cb99-4143-f2ed-ab3376f660e5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading VisualizeExecutionPlan library ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_plan(dfTest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "id": "FBkj8EqdYjqh",
        "outputId": "a3c2d4ba-4313-4f2b-cb0c-80a34286f576"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: Execution Plan Pages: 1 -->\n<svg width=\"281pt\" height=\"451pt\"\n viewBox=\"0.00 0.00 281.00 451.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 447)\">\n<title>Execution Plan</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-447 277,-447 277,4 -4,4\"/>\n<text text-anchor=\"middle\" x=\"136.5\" y=\"-33.4\" font-family=\"Times,serif\" font-size=\"12.00\">Execution Plan</text>\n<text text-anchor=\"middle\" x=\"136.5\" y=\"-20.4\" font-family=\"Times,serif\" font-size=\"12.00\">Sizes are estimates based on table statistics</text>\n<text text-anchor=\"middle\" x=\"136.5\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\">They are not reliable anymore after joins are involved!</text>\n<!-- 5 -->\n<g id=\"node1\" class=\"node\">\n<title>5</title>\n<g id=\"a_node1\"><a xlink:title=\"RESULT\">\n<polygon fill=\"white\" stroke=\"black\" points=\"170,-83 103,-83 103,-47 170,-47 170,-83\"/>\n<text text-anchor=\"middle\" x=\"136.5\" y=\"-61.3\" font-family=\"Times,serif\" font-size=\"14.00\">RESULT</text>\n</a>\n</g>\n</g>\n<!-- 6 -->\n<g id=\"node2\" class=\"node\">\n<title>6</title>\n<g id=\"a_node2\"><a xlink:title=\"AdaptiveSparkPlan isFinalPlan=false\">\n<polygon fill=\"white\" stroke=\"black\" points=\"197.5,-155 75.5,-155 75.5,-119 197.5,-119 197.5,-155\"/>\n<text text-anchor=\"middle\" x=\"136.5\" y=\"-133.3\" font-family=\"Times,serif\" font-size=\"14.00\">AdaptiveSparkPlan</text>\n</a>\n</g>\n</g>\n<!-- 6&#45;&gt;5 -->\n<g id=\"edge1\" class=\"edge\">\n<title>6&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M136.5,-118.7C136.5,-110.98 136.5,-101.71 136.5,-93.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"140,-93.1 136.5,-83.1 133,-93.1 140,-93.1\"/>\n</g>\n<!-- 7 -->\n<g id=\"node3\" class=\"node\">\n<title>7</title>\n<g id=\"a_node3\"><a xlink:title=\"HashAggregate(keys=[longitude#52, latitude#53], functions=[], output=[longitude#52, latitude#53])\">\n<polygon fill=\"white\" stroke=\"black\" points=\"187,-227 86,-227 86,-191 187,-191 187,-227\"/>\n<text text-anchor=\"middle\" x=\"136.5\" y=\"-205.3\" font-family=\"Times,serif\" font-size=\"14.00\">HashAggregate</text>\n</a>\n</g>\n</g>\n<!-- 7&#45;&gt;6 -->\n<g id=\"edge2\" class=\"edge\">\n<title>7&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M136.5,-190.7C136.5,-182.98 136.5,-173.71 136.5,-165.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"140,-165.1 136.5,-155.1 133,-165.1 140,-165.1\"/>\n</g>\n<!-- 8 -->\n<g id=\"node4\" class=\"node\">\n<title>8</title>\n<g id=\"a_node4\"><a xlink:title=\"Exchange hashpartitioning(longitude#52, latitude#53, 200), ENSURE_REQUIREMENTS, [plan_id=106]\">\n<polygon fill=\"white\" stroke=\"black\" points=\"171.5,-299 101.5,-299 101.5,-263 171.5,-263 171.5,-299\"/>\n<text text-anchor=\"middle\" x=\"136.5\" y=\"-277.3\" font-family=\"Times,serif\" font-size=\"14.00\">Exchange</text>\n</a>\n</g>\n</g>\n<!-- 8&#45;&gt;7 -->\n<g id=\"edge3\" class=\"edge\">\n<title>8&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M136.5,-262.7C136.5,-254.98 136.5,-245.71 136.5,-237.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"140,-237.1 136.5,-227.1 133,-237.1 140,-237.1\"/>\n</g>\n<!-- 9 -->\n<g id=\"node5\" class=\"node\">\n<title>9</title>\n<g id=\"a_node5\"><a xlink:title=\"HashAggregate(keys=[knownfloatingpointnormalized(normalizenanandzero(longitude#52)) AS longitude#52, knownfloatingpointnormalized(normalizenanandzero(latitude#53)) AS latitude#53], functions=[], output=[longitude#52, latitude#53])\">\n<polygon fill=\"white\" stroke=\"black\" points=\"187,-371 86,-371 86,-335 187,-335 187,-371\"/>\n<text text-anchor=\"middle\" x=\"136.5\" y=\"-349.3\" font-family=\"Times,serif\" font-size=\"14.00\">HashAggregate</text>\n</a>\n</g>\n</g>\n<!-- 9&#45;&gt;8 -->\n<g id=\"edge4\" class=\"edge\">\n<title>9&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M136.5,-334.7C136.5,-326.98 136.5,-317.71 136.5,-309.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"140,-309.1 136.5,-299.1 133,-309.1 140,-309.1\"/>\n</g>\n<!-- 10 -->\n<g id=\"node6\" class=\"node\">\n<title>10</title>\n<g id=\"a_node6\"><a xlink:title=\"FileScan csv [longitude#52,latitude#53] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/sample_data/california_housing_test.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;longitude:double,latitude:double&gt;\">\n<polygon fill=\"white\" stroke=\"black\" points=\"168.5,-443 104.5,-443 104.5,-407 168.5,-407 168.5,-443\"/>\n<text text-anchor=\"middle\" x=\"136.5\" y=\"-421.3\" font-family=\"Times,serif\" font-size=\"14.00\">FileScan</text>\n</a>\n</g>\n</g>\n<!-- 10&#45;&gt;9 -->\n<g id=\"edge5\" class=\"edge\">\n<title>10&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M136.5,-406.7C136.5,-398.98 136.5,-389.71 136.5,-381.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"140,-381.1 136.5,-371.1 133,-381.1 140,-381.1\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x79a7d55c14d0>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(df.join)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qf9tfcLwYyRn",
        "outputId": "b822de21-65fb-49a0-e803-acc48257007f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on method join in module pyspark.sql.dataframe:\n",
            "\n",
            "join(other: 'DataFrame', on: Union[str, List[str], pyspark.sql.column.Column, List[pyspark.sql.column.Column], NoneType] = None, how: Optional[str] = None) -> 'DataFrame' method of pyspark.sql.dataframe.DataFrame instance\n",
            "    Joins with another :class:`DataFrame`, using the given join expression.\n",
            "    \n",
            "    .. versionadded:: 1.3.0\n",
            "    \n",
            "    .. versionchanged:: 3.4.0\n",
            "        Supports Spark Connect.\n",
            "    \n",
            "    Parameters\n",
            "    ----------\n",
            "    other : :class:`DataFrame`\n",
            "        Right side of the join\n",
            "    on : str, list or :class:`Column`, optional\n",
            "        a string for the join column name, a list of column names,\n",
            "        a join expression (Column), or a list of Columns.\n",
            "        If `on` is a string or a list of strings indicating the name of the join column(s),\n",
            "        the column(s) must exist on both sides, and this performs an equi-join.\n",
            "    how : str, optional\n",
            "        default ``inner``. Must be one of: ``inner``, ``cross``, ``outer``,\n",
            "        ``full``, ``fullouter``, ``full_outer``, ``left``, ``leftouter``, ``left_outer``,\n",
            "        ``right``, ``rightouter``, ``right_outer``, ``semi``, ``leftsemi``, ``left_semi``,\n",
            "        ``anti``, ``leftanti`` and ``left_anti``.\n",
            "    \n",
            "    Returns\n",
            "    -------\n",
            "    :class:`DataFrame`\n",
            "        Joined DataFrame.\n",
            "    \n",
            "    Examples\n",
            "    --------\n",
            "    The following performs a full outer join between ``df1`` and ``df2``.\n",
            "    \n",
            "    >>> from pyspark.sql import Row\n",
            "    >>> from pyspark.sql.functions import desc\n",
            "    >>> df = spark.createDataFrame([(2, \"Alice\"), (5, \"Bob\")]).toDF(\"age\", \"name\")\n",
            "    >>> df2 = spark.createDataFrame([Row(height=80, name=\"Tom\"), Row(height=85, name=\"Bob\")])\n",
            "    >>> df3 = spark.createDataFrame([Row(age=2, name=\"Alice\"), Row(age=5, name=\"Bob\")])\n",
            "    >>> df4 = spark.createDataFrame([\n",
            "    ...     Row(age=10, height=80, name=\"Alice\"),\n",
            "    ...     Row(age=5, height=None, name=\"Bob\"),\n",
            "    ...     Row(age=None, height=None, name=\"Tom\"),\n",
            "    ...     Row(age=None, height=None, name=None),\n",
            "    ... ])\n",
            "    \n",
            "    Inner join on columns (default)\n",
            "    \n",
            "    >>> df.join(df2, 'name').select(df.name, df2.height).show()\n",
            "    +----+------+\n",
            "    |name|height|\n",
            "    +----+------+\n",
            "    | Bob|    85|\n",
            "    +----+------+\n",
            "    >>> df.join(df4, ['name', 'age']).select(df.name, df.age).show()\n",
            "    +----+---+\n",
            "    |name|age|\n",
            "    +----+---+\n",
            "    | Bob|  5|\n",
            "    +----+---+\n",
            "    \n",
            "    Outer join for both DataFrames on the 'name' column.\n",
            "    \n",
            "    >>> df.join(df2, df.name == df2.name, 'outer').select(\n",
            "    ...     df.name, df2.height).sort(desc(\"name\")).show()\n",
            "    +-----+------+\n",
            "    | name|height|\n",
            "    +-----+------+\n",
            "    |  Bob|    85|\n",
            "    |Alice|  NULL|\n",
            "    | NULL|    80|\n",
            "    +-----+------+\n",
            "    >>> df.join(df2, 'name', 'outer').select('name', 'height').sort(desc(\"name\")).show()\n",
            "    +-----+------+\n",
            "    | name|height|\n",
            "    +-----+------+\n",
            "    |  Tom|    80|\n",
            "    |  Bob|    85|\n",
            "    |Alice|  NULL|\n",
            "    +-----+------+\n",
            "    \n",
            "    Outer join for both DataFrams with multiple columns.\n",
            "    \n",
            "    >>> df.join(\n",
            "    ...     df3,\n",
            "    ...     [df.name == df3.name, df.age == df3.age],\n",
            "    ...     'outer'\n",
            "    ... ).select(df.name, df3.age).show()\n",
            "    +-----+---+\n",
            "    | name|age|\n",
            "    +-----+---+\n",
            "    |Alice|  2|\n",
            "    |  Bob|  5|\n",
            "    +-----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.join(dfTest,(df.longitude==dfTest.longitude) & (df.latitude==dfTest.latitude),'inner').show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oT8V7jn-YySv",
        "outputId": "e18c6ee5-1a3a-4422-96f8-3b10da4480b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------+--------+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|longitude|latitude|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------+--------+\n",
            "|  -115.49|   32.67|              29.0|     1523.0|         440.0|    1302.0|     393.0|       1.1311|           84700.0|  -115.49|   32.67|\n",
            "|  -115.49|   32.67|              25.0|     2322.0|         573.0|    2185.0|     602.0|        1.375|           70100.0|  -115.49|   32.67|\n",
            "|  -115.52|   32.98|              32.0|     1615.0|         382.0|    1307.0|     345.0|       1.4583|           58600.0|  -115.52|   32.98|\n",
            "|  -115.56|   32.78|              46.0|     2511.0|         490.0|    1583.0|     469.0|       3.0603|           70800.0|  -115.56|   32.78|\n",
            "|  -115.56|   32.78|              35.0|     1185.0|         202.0|     615.0|     191.0|       4.6154|           86200.0|  -115.56|   32.78|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.join(dfTest,['longitude','latitude'],'inner').show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypjH0pb1aY2A",
        "outputId": "296e221c-e2b1-43af-d8a1-3720ac6f42ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|  -115.49|   32.67|              29.0|     1523.0|         440.0|    1302.0|     393.0|       1.1311|           84700.0|\n",
            "|  -115.49|   32.67|              25.0|     2322.0|         573.0|    2185.0|     602.0|        1.375|           70100.0|\n",
            "|  -115.52|   32.98|              32.0|     1615.0|         382.0|    1307.0|     345.0|       1.4583|           58600.0|\n",
            "|  -115.56|   32.78|              46.0|     2511.0|         490.0|    1583.0|     469.0|       3.0603|           70800.0|\n",
            "|  -115.56|   32.78|              35.0|     1185.0|         202.0|     615.0|     191.0|       4.6154|           86200.0|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.summary().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGnhaV_RaY3O",
        "outputId": "1a32ccce-be83-417d-a7e4-8828ad525091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------------------+------------------+------------------+-----------------+-----------------+------------------+-----------------+------------------+------------------+\n",
            "|summary|          longitude|          latitude|housing_median_age|      total_rooms|   total_bedrooms|        population|       households|     median_income|median_house_value|\n",
            "+-------+-------------------+------------------+------------------+-----------------+-----------------+------------------+-----------------+------------------+------------------+\n",
            "|  count|              17000|             17000|             17000|            17000|            17000|             17000|            17000|             17000|             17000|\n",
            "|   mean|-119.56210823529375|  35.6252247058827| 28.58935294117647|2643.664411764706|539.4108235294118|1429.5739411764705|501.2219411764706| 3.883578100000021|207300.91235294117|\n",
            "| stddev| 2.0051664084260357|2.1373397946570867|12.586936981660406|2179.947071452777|421.4994515798648| 1147.852959159527|384.5208408559016|1.9081565183791036|115983.76438720895|\n",
            "|    min|            -124.35|             32.54|               1.0|              2.0|              1.0|               3.0|              1.0|            0.4999|           14999.0|\n",
            "|    25%|            -121.79|             33.93|              18.0|           1462.0|            297.0|             789.0|            282.0|            2.5662|          119400.0|\n",
            "|    50%|            -118.49|             34.25|              29.0|           2127.0|            434.0|            1167.0|            409.0|            3.5445|          180400.0|\n",
            "|    75%|             -118.0|             37.72|              37.0|           3150.0|            648.0|            1720.0|            605.0|            4.7639|          265000.0|\n",
            "|    max|            -114.31|             41.95|              52.0|          37937.0|           6445.0|           35682.0|           6082.0|           15.0001|          500001.0|\n",
            "+-------+-------------------+------------------+------------------+-----------------+-----------------+------------------+-----------------+------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *\n",
        "df.select(avg(df.total_rooms)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckU5pbVRb1AB",
        "outputId": "649876f8-3838-4674-dbeb-f58a2e6b264b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+\n",
            "| avg(total_rooms)|\n",
            "+-----------------+\n",
            "|2643.664411764706|\n",
            "+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(avg(df.total_rooms),min(df.total_rooms),max((df.total_rooms))).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_MQM35ScWqE",
        "outputId": "101c7b5f-5fb9-452c-f06c-f62e22b1fad9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+----------------+----------------+\n",
            "| avg(total_rooms)|min(total_rooms)|max(total_rooms)|\n",
            "+-----------------+----------------+----------------+\n",
            "|2643.664411764706|             2.0|         37937.0|\n",
            "+-----------------+----------------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy(df.longitude,df.latitude).avg('total_rooms').show(8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2V3DFc5yb1BY",
        "outputId": "58f108fb-0017-407d-ce28-382d679040fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+----------------+\n",
            "|longitude|latitude|avg(total_rooms)|\n",
            "+---------+--------+----------------+\n",
            "|  -116.09|   34.15|          9444.0|\n",
            "|  -116.31|   33.66|          4497.0|\n",
            "|   -116.9|   33.22|          4132.0|\n",
            "|  -116.96|   32.86|          3064.0|\n",
            "|  -116.97|   32.76|          2765.5|\n",
            "|  -116.99|   33.77|         10352.0|\n",
            "|  -117.03|   33.18|          5391.0|\n",
            "|  -117.19|   33.69|          6484.0|\n",
            "+---------+--------+----------------+\n",
            "only showing top 8 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.window import *\n",
        "windowPartition = Window.partitionBy(['latitude','longitude']).orderBy(\"total_rooms\")\n",
        "df.withColumn(\"rownum\",row_number().over(windowPartition)).show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xadX1qNiLAg",
        "outputId": "0d1dcf02-21b7-4c2e-ea69-e183b93483d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+------+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|rownum|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+------+\n",
            "|  -117.04|   32.54|               7.0|      938.0|         297.0|    1187.0|     282.0|       1.2667|           67500.0|     1|\n",
            "|  -117.09|   32.55|               8.0|     6533.0|        1217.0|    4797.0|    1177.0|       3.9583|          144400.0|     1|\n",
            "|  -117.06|   32.55|               5.0|     3223.0|         940.0|    3284.0|     854.0|       1.4384|          108800.0|     1|\n",
            "|  -117.04|   32.55|              15.0|     2206.0|         648.0|    2511.0|     648.0|       1.6348|           93200.0|     1|\n",
            "|  -117.12|   32.56|              20.0|     2524.0|         682.0|    1819.0|     560.0|       2.9286|          257700.0|     1|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-Ninja3tjwio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.window import *\n",
        "windowPartition = Window.partitionBy(['latitude']).orderBy(\"total_rooms\")\n",
        "df.withColumn(\"rownum\",row_number().over(windowPartition)).show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8qwlo77jwj8",
        "outputId": "025b2d68-bbb7-4cf6-95c9-26dba834d47a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+------+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|rownum|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+------+\n",
            "|  -117.04|   32.54|               7.0|      938.0|         297.0|    1187.0|     282.0|       1.2667|           67500.0|     1|\n",
            "|  -117.04|   32.55|              15.0|     2206.0|         648.0|    2511.0|     648.0|       1.6348|           93200.0|     1|\n",
            "|  -117.06|   32.55|               5.0|     3223.0|         940.0|    3284.0|     854.0|       1.4384|          108800.0|     2|\n",
            "|  -117.09|   32.55|               8.0|     6533.0|        1217.0|    4797.0|    1177.0|       3.9583|          144400.0|     3|\n",
            "|  -117.05|   32.56|              17.0|      985.0|         233.0|     811.0|     223.0|        2.875|          134500.0|     1|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.withColumn('id',monotonically_increasing_id()).show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0skPOS6Gkf6J",
        "outputId": "5c02ac1b-de52-41c1-b5a3-5911bf4d1e7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value| id|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---+\n",
            "|  -114.31|   34.19|              15.0|     5612.0|        1283.0|    1015.0|     472.0|       1.4936|           66900.0|  0|\n",
            "|  -114.47|    34.4|              19.0|     7650.0|        1901.0|    1129.0|     463.0|         1.82|           80100.0|  1|\n",
            "|  -114.56|   33.69|              17.0|      720.0|         174.0|     333.0|     117.0|       1.6509|           85700.0|  2|\n",
            "|  -114.57|   33.64|              14.0|     1501.0|         337.0|     515.0|     226.0|       3.1917|           73400.0|  3|\n",
            "|  -114.57|   33.57|              20.0|     1454.0|         326.0|     624.0|     262.0|        1.925|           65500.0|  4|\n",
            "|  -114.58|   33.63|              29.0|     1387.0|         236.0|     671.0|     239.0|       3.3438|           74000.0|  5|\n",
            "|  -114.58|   33.61|              25.0|     2907.0|         680.0|    1841.0|     633.0|       2.6768|           82400.0|  6|\n",
            "|  -114.59|   34.83|              41.0|      812.0|         168.0|     375.0|     158.0|       1.7083|           48500.0|  7|\n",
            "|  -114.59|   33.61|              34.0|     4789.0|        1175.0|    3134.0|    1056.0|       2.1782|           58400.0|  8|\n",
            "|   -114.6|   34.83|              46.0|     1497.0|         309.0|     787.0|     271.0|       2.1908|           48100.0|  9|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(df.latitude,sha1(df.longitude.cast('string'))).show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VEFSefeljic",
        "outputId": "443679e8-94c4-45af-c391-a0c253447c70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------------------------------+\n",
            "|latitude|sha1(CAST(longitude AS STRING))|\n",
            "+--------+-------------------------------+\n",
            "|   34.19|           bbfd561c970711cb4...|\n",
            "|    34.4|           4780ba04fe9b76321...|\n",
            "|   33.69|           ec15d7818706bdcb2...|\n",
            "|   33.64|           750f79fb96bd9697c...|\n",
            "|   33.57|           750f79fb96bd9697c...|\n",
            "+--------+-------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}